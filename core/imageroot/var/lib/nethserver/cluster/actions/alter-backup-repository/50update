#!/usr/bin/env python3

#
# Copyright (C) 2026 Nethesis S.r.l.
# SPDX-License-Identifier: GPL-3.0-or-later
#

import os
import sys
import json
import agent
import cluster.backup
import subprocess

def main():
    request = json.load(sys.stdin)
    rdb = agent.redis_connect(privileged=True)

    provider = request['provider']
    destination_uuid = request['id']
    parameters = request.get('parameters', {})

    if not rdb.hget(f'private/nodes/backup_destination/rclone_conf', destination_uuid):
        agent.set_status('validation-failed')
        json.dump([{'field':'id','parameter':'id','value': destination_uuid,'error':'backup_repository_not_found'}], fp=sys.stdout)
        sys.exit(2)

    if provider != rdb.hget(f'cluster/backup_repository/{destination_uuid}', 'provider'):
        agent.set_status('validation-failed')
        json.dump([{'field':'provider','parameter':'provider','value': provider,'error':'backup_provider_mismatch'}], fp=sys.stdout)
        sys.exit(3)

    url = rdb.hget(f'cluster/backup_repository/{destination_uuid}', 'url')
    rclone_conf, destination_basepath = cluster.backup.generate_rclone_conf(destination_uuid, url, provider, parameters)

    # Prepare a list of tasks, one for each node, to run in parallel:
    node_add_backup_repository_tasks = []
    for node_id in set(rdb.hvals('cluster/module_node')):
        node_add_backup_repository_tasks.append({
            "action": "validate-backup-destination",
            "agent": f"node/{node_id}",
            "extra": {'isNotificationHidden': True},
            "data": {
                "id": destination_uuid,
                "basepath": destination_basepath,
                "rclone_conf": rclone_conf,
            },
        })
    node_task_results = agent.tasks.runp(
        node_add_backup_repository_tasks,
        endpoint="redis://cluster-leader",
    )
    # Fail if all nodes cannot reach the backup repository:
    if all(ntr["exit_code"] != 0 for ntr in node_task_results):
        agent.set_status('validation-failed')
        json.dump([{'field':'parameters','parameter':'parameters','value':'','error':'backup_repository_not_accessible'}], fp=sys.stdout)
        sys.exit(4)

    if 'name' in request:
        rname = request['name']
    else:
        rname = rdb.hget(f'cluster/backup_repository/{destination_uuid}', 'name') or ""

    if not rname:
        rname = cluster.backup.get_default_backup_repository_name(provider, url, destination_uuid)

    public_data = {'url': url, 'name': rname, 'provider': request['provider']}
    trx = rdb.pipeline()
    trx.hdel('private/nodes/backup_destination/rclone_conf', destination_uuid)
    trx.hset('private/nodes/backup_destination/rclone_conf', destination_uuid, rclone_conf)
    trx.hset('private/nodes/backup_destination/parameters/' + destination_uuid, mapping={
        'basepath': destination_basepath,
    })
    trx.delete(f'cluster/backup_repository/{destination_uuid}')
    trx.hset(f'cluster/backup_repository/{destination_uuid}', mapping=public_data)
    trx.publish(f"cluster/event/backup-destination-changed", json.dumps({
        "destination_id": rid,
    }))
    if not trx.execute():
        sys.exit(1)

if __name__ == "__main__":
    main()
